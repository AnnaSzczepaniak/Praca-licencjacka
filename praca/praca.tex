\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{polski}
\usepackage{hyperref}
\usepackage[polish, chapter]{dyschemist}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}


\newcommand{\vr}[1]{\mathbf{#1}}
\newcommand{\mx}[1]{{#1}}


\author{Anna Szczepaniak}
\title{Algorytm dekompozycji QR}
\begin{document}

\maketitle


\tableofcontents

%\chapter{Wstęp}

\chapter{Preliminaria}

W niniejszym rozdziale przypomniane zostaną wybrane elementy z zakresu algebry liniowej, potrzebne do wyjaśnienia działania algorytmu QR.

%\section{Elementy algebry liniowej} 

Niniejszą część rozpocznijmy od zdefiniowania pojęcia macierzy. Warto nadmienić, że w znaczącej części literatury - pojęcie te nie jest definiowane w sposób matematycznie precyzyjny.

\begin{definition}[Macierz \cite{poreda11}]
Niech $n,m \in \setN$. Macierzą o $m$ wierszach oraz $n$ kolumnach (nazywaną również macierzą o wymiarach $m \times n$) i wyrazach w ciele $\setR$ nazywamy funkcję 
$$
\mx{A}: \set{1,2, \ldots ,m}\times \set{1,2, \ldots ,n} \to \setR.
$$
Wartością funkcji dla argumentu $(i,j)$, gdzie $i \in \set{1,2, \ldots ,m}$, $j \in \set{1,2, \ldots ,n}$ jest element $a_{ij} \in \setR$. Macierz często zapisujemy w postaci tabeli
$$
\mx{A} = \begin{bmatrix}
 a_{11} & a_{12} & \cdots & a_{1n} \\
         a_{21} & a_{22} & \cdots & a_{2n} \\
         \vdots & \vdots & \ddots & \vdots \\
         a_{m1} & a_{m2} & \cdots & a_{mn} \\
\end{bmatrix}.
$$

Przez $\setR^{m \times n}$ oznaczmy zbiór wszystkich macierzy o wymiarach $m \times n$ i elementach z $\setR$ .
\end{definition}

Macierze posiadają wiele istotnych dla nas podklas, posiadający określone cechy. Wymieńmy kilka typów macierzy, szczególnie interesujących z perspektywy omawianego przez nas tematu.

\begin{definition}[Macierz kwadratowa\citep{poreda11}] \label{definicja-macierzy}
Macierzą kwadratową o wymiarze $n$ na $n$ nazywamy macierz o równej liczbie wierszy i kolumn. Liczbę $n$ nazywamy wtedy stopniem macierzy kwadratowej.
\end{definition}

\begin{definition}[Macierz diagonalna\citep{poreda11}]
Jeśli w macierzy kwadratowej $[a_{ij}]$ wszystkie elementy poza główną przekątną są równe zeru, to taką macierz nazywamy macierzą diagonalną, oznaczamy ją jako $diag(a_{11}, a_{22},\ldots,a_{nn})$.
\end{definition}

\begin{definition}[Macierz jednostkowa \citep{poreda11}]
Macierz jednostkową stopnia $n$ nazywamy taką macierz diagonalną, w której wszystkie elementy na głównej przekątnej są równe 1.
\end{definition}

\begin{definition}[Macierz symetryczna]
Macierzą symetryczną nazywamy macierz kwadratową $\mx{A}=[a_{ij}]$, której wyrazy spełniają warunek 
$$
\forall_{i,j \in \set{1,\ldots,n}} \quad a_{ij}=a_{ji}.
$$
\end{definition}

\begin{definition}[Macierz trójkątna górna oraz trójkątna dolna\citep{poreda11}]
Jeśli w macierzy kwadratowej $[a_{ij}]$ wszystkie elementy poniżej głównej przekątnej są równe $0$, to taką macierz nazywamy macierzą trójkątną górną.
Analogicznie jeśli w macierzy kwadratowej $[a_{ij}]$ wszystkie elementy powyżej głównej przekątnej są równe $0$ to taką macierz nazywamy trójkątną dolną.
\end{definition}

\begin{definition}
Niech $\mx{A}=[a_{ij}] \in \setR^{m \times n}$. Wtedy macierz $D \in \setR^{n \times m}$ spełniająca warunek taki, że
$$
d_{ij} = a_{ji},
$$
dla dowolnych $i \in \set{1,\ldots, n}$ oraz $j \in \set{1,\ldots,m}$ nazywamy macierzą transponowaną do $A$. Z reguły tę macierz $D$ oznaczamy symbolem $\transpose{A}$.
\end{definition}

%TODO proszę kontynuować poprawki definicji poniżej

\begin{definition}[Iloczyn macierzy\citep{poreda11}]
Niech $\mx{A}\in \mx{M}_{m\times n}(\set{K})$ i $\mx{B}\in \mx{M}_{k\times m}(\set{K})$. Jeśli
$$
\mx{A} = \begin{bmatrix}
 a_{11} & a_{12} & \cdots & a_{1n} \\
         a_{21} & a_{22} & \cdots & a_{2n} \\
         \vdots & \vdots & \ddots & \vdots \\
         a_{m1} & a_{m2} & \cdots & a_{mn} \\
\end{bmatrix}.
$$ 
i 
$$
\mx{B} = \begin{bmatrix}
 b_{11} & b_{12} & \cdots & b_{1m} \\
         b_{21} & b_{22} & \cdots & b_{2m} \\
         \vdots & \vdots & \ddots & \vdots \\
         b_{k1} & b_{k2} & \cdots & b_{km} \\
\end{bmatrix}.
$$
to iloczynem macierzy $\mx{B}$ i $\mx{A}$ nazywamy macierz $\mx{C}$ taką, że
$$
\mx{C} = [c_{lj}]_{j=1,\ldots,n}^{l=1,\ldots,k}
$$
i
$$
c_{lj}= \sum_{l=1}^{m} b_{li} \cdot a_{ij}
$$.
\end{definition}

%[a_{ij}]_{i\le m, j\le k}$ będzie macierzą o wymiarach $m\times k$, a $\mx{B}=[b_{ij}]_{i\le k, j\le n}$ macierzą o wymiarach $k\times n$. Iloczynem macierzy $\mx{A}$,$\mx{B}$ nazywamy macierz $\mx{A} \mx{B}=[c_{ij}]_{i\le m, j\le n}$ o wymiarach $m\times n$, gdzie dla 
$$
i=1,\ldots,m, j=1,\ldots,n 
$$.


\begin{definition}[Macierz odwrotna\citep{poreda11}]
Macierz $\mx{A}$ ze zbioru $\mx{M}_{n}(\set{K})$ nazywamy macierzą odwracalną, jeśli istnieje macierz $\mx{B}$ w zbiorze.
Niech A będzie macierzą kwadratową ustalonego stopnia. Macierz A jest odwracalna, jeśli istnieje taka macierz B, że zachodzi
$$
A\cdot B=B\cdot A=I
$$, 
gdzie I jest macierzą jednostkową. Macierz B nazywa się wówczas macierzą odwrotną do macierzy A i oznacza się przez  $A^{-1}.$
\end{definition}

\begin{definition}
Macierz A nazywamy macierzą nieosobliwą, jeśli istnieje macierz B, która jest do niej odwrotna.
\end{definition}  

\begin{definition}
Macierzą ortogonalną nazywamy macierz kwadratową $A\in M_{n}(R)$ o elementach będących liczbami rzeczywistymi spełniająca równość:
$$
A^{T}\cdot A=A\cdot A^{T}=I_{n}
$$, 
gdzie $I_{n}$ oznacza macierz jednostkową wymiaru n, $A^{T}$ oznacza macierz transponowaną względem A.
\end{definition}

\begin{definition}
Dwie macierze kwadratowe A i B nazywamy macierzami podobnymi, jeśli istnieje taka macierz nieosobliwa P, że zachodzi związek: 
$$
B=P^{-1}\cdot A\cdot P
$$.
\end{definition}


\section{Definicje dotyczące wektorów} 

\begin{definition}
Jeżeli $\vr{p},\vr{q}\in \set{R}^{n}$, to parę $(\vr{p},\vr{q})$ nazywamy wektorem zaczepionym o początku $\vr{p}$ i końcu $\vr{q}$.
\end{definition}

\begin{definition}
Niech $\vr{v_{1}},..., \vr{v_{n}}$ będą różnymi elementami przestrzeni liniowe V. Zbiór wektorów ${\vr{v_{1}},...,\vr{v_{n}}}$ nazywamy liniowo niezależnymi jeżeli 
$$
\forall_{a_{1},...,a_{n}\in \mathbb{R}} (a_{1}\cdot v_{1} + ... + a_{n}\cdot v_{n} = 0 \implies a_{1}=...=a_{n}=0)
$$ 
\end{definition}

\section{Definicje dotyczące wyznacznika macierzy, jej wartości własnej oraz wektorów własnych.}

\begin{definition}[??]
Niech będzie dana macierz kwadratowa A stopnia n. Wyznacznikiem nazywamy takie odwzorowanie, które danej macierzy $A$ wymiaru $n \times n$ przyporządkowuje dokładnie jedną liczbę rzeczywistą $\det A$. Jeśli macierz jest stopnia $n = 1$, to jej wyznacznik $\det A  = a_{11}$. 
Jeśli stopień macierzy jest większy niż 1, to jej wyznacznik obliczamy według następującego wzoru: 
$$
\det A = \sum_{i=1}^{n} (-1)^{i+j}\cdot a_{ij}\cdot \det M_{ij},
$$
gdzie $\det M_{ij}$ oznacza wyznacznik macierzy powstałej z macierzy A przez skreślenie i-tego wiersza i j-tej kolumny.
\end{definition}

\begin{definition}
Niech $\mx{B}$ będzie macierzą wymiaru $m$ na $m$ i niech $I$ będzie macierzą jednostkową wymiaru $m$ na $m$. Wówczas wartościami własnymi macierzy $B$ nazywamy takie $\lambda \in \setC$, które spełniają następujące równanie:
$$
\det (\mx{B}-\lambda\cdot \mx{I})=0. 
$$ 
Ponadto każdy wektor $\vr{v} \in \setR^m$ spełniają dwa warunki
\begin{enumerate}
\item Nie będący wektorem zerowym - $v \neq 0$, oraz
\item spełniającym równość
$$
\mx{B} \vr{v} = \lambda \vr{v},
$$
\end{enumerate}
nazywać będziemy wektorem własnym stowarzyszonym z wartością własną $\lambda$.
\end{definition}

\chapter{Algorytm QR}

W tym rozdziale zaprezentujemy elementy teorii dokonywania rozkładów QR macierzy. Rozpoczniemy od sformułowania i udowodnienia twierdzenia o istnieniu takiego rozkładu. Wiele analizowanych pozycji literaturowych sygnalizowało posiadanie dowodu poniższego twierdzenia. W naszej ocenie prezentowane tam dowody bliższe są jednak jedynie ich szkicowi. W efekcie pracy własnej poniżej prezentujemy własne opracowanie dowodu twierdzenia o istnieniu rozkładu QR, stworzonego na podstawie szkiców omówionych w literaturze. 

\begin{theorem}[O rozkładzie QR]\label{theorem-qr-docomposition}
Niech $\mx{A} \in \setR^{m \times n}$, gdzie $m\ge n$, której kolumny są liniowo niezależne. Istnieje wtedy jedyny rozkład 
$$
\mx{A} = \mx{Q} \mx{R}
$$ 
na dwa czynniki
\begin{itemize}
\item macierz $\mx{Q}$ taką, że 
$$
Q^{T}\cdot Q=D,
$$
gdzie $D= diag (d_{1}, d_{2}, ..., d_{n})$, oraz $d_{k}>0$ dla $k = 1, 2, \ldots, n$, oraz
\item macierz trójkątną górną $\mx{R}$ spełniającą dodatkowo warunek 
$$
r_{kk}= 1 
$$ 
dla $k = 1, 2, \ldots, n$.
\end{itemize} 
\end{theorem}

\begin{theorem}[Twierdzenie(Grama-Schmidta)\citep{poreda11}]
Dla każdego układu liniowo niezależnego wektorów $\vr(x_{1}),\ldots,\vr(x_{n})$ w przestrzeni euklidesowej istnieje układ ortonormalny $(\vr(b_{1},\ldots,b_{n})$ taki, że 
$$
span(\vr(b_{1},\ldots,b_{k}) = span(\vr(x_{1},\ldots,x_{k})
$$
dla każdej liczby $k$ ze zbioru $(1,\ldots,n)$.
\end{theorem}

\begin{proof}[Dowód\citep{poreda11}]
Oczywiście wektory $\vr(x_{i})$ są niezerowe, zatem mają długość dodatnią. Niech więc
$$
\vr(b_{1})=(1\div\Vert\vr(x_{1})\Vert)\cdot\vr(x_{1})
$$

\end{proof}
TODO twierdzenie Grama Schmidta z poredy + dowód

\begin{lemma}[O postaci macierzowej w algorytmie Grama-Schmidta]
Powyżej omówiony algorytm Grama Schmidta jest równoważny następującym transformacjom macierzy: Załóżmy, że wektory $\vr{v_1}, \ldots, \vr{v_n}$ są kolumnami macierzy $\mx{A}$ oraz że są liniowo niezależna. Wtedy z twierdzenia \ref{theorem-gram-schmidt} istnieją wektory $\vr{u_1}, \ldots, \vr{u_n}$ , które są transformacją wektorów v, przez algorytm Grama Schmidta. Niech $\mx{U}$ będzie macierza utworzoną kolumnowo z tych wektorów U. Wtedy
$$
U = A \cdot \ldots
$$
\end{lemma}
\begin{proof}

\end{proof}

\begin{lemma}[O iloczynie macierzy trójkątnych górnych]
... iloczyn dwóch macierzy trójkątnych górnych jest macierzą trójkątną górną
\end{lemma}

\begin{lemma}[O odwracaniu macierzy trójkątnej górnej]
...
\end{lemma}

\begin{lemma}[O macierzy zmieniającej znak na przekątnej]

\end{lemma}

\begin{proof}[Dowód twierdzenia \ref{theorem-qr-docomposition}]

\end{proof}

\noindent \textbf{Dowód twierdzenia 3.1}\\
Podane wyżej twierdzenie jest przekształceniem
procesu ortogonalizacji Grama-Schmidta. Jeśli zastosujemy Grama-Schmidta do kolumn $a_{i}$ macierzy
 $A = [a_{1}, a_{2}, ..., a_{n}]$ od lewej do prawej, otrzymamy
sekwencje ortonormalnych wektorów od $q_{1}$ do $q_{n}$ obejmujących tę samą przestrzeń:
te ortogonalne wektory są kolumnami Q. Gram-Schmidt również wylicza
współczynniki wyrażające każdą kolumnę $a_{i}$
 jako liniową kombinację $q_{1}$ przez 
 $$q_{i}: a_{i}= \sum_{j=1}^i r_{ji}\cdot q_{i}, $$ 
 gdzie $r_{ji}$ to współczynniki macierzy R.
 



Algorytm QR został wynaleziony w 1961 roku przez Francisa i Kubłanowską. Jest jedną z efektywniejszych znanych metod rozwiązywania pełnego zadania własnego dla macierzy symetrycznych lub niesymetrycznych.
W podstawowym algorytmie QR tworzy się ciąg macierzy $A= A_{0}, A_{1}, A_{2}, ...$ taki, że 
$$ A_{s}=Q_{s}R_{s},$$
$$R_{s}Q_{s}=A_{s+1},$$
$$(s=0, 1, ...),$$ 
gdzie $Q_{s}$ jest macierzą ortogonalną, a $R_{s}$ - trójkątną górną. Łatwo widać, że z twierdzenia o rozkładzie QR wynika, że ciąg $A_{s}$ $(s=0, 1, ...)$ jest w zasadzie określony jednoznacznie. Ponieważ 
$$ A_{s+1}=R_{s}Q_{s}=Q_{s}^{T}A_{s}Q_{s},$$ 
więc każdy krok w algorytmie QR jest przekształceniem przez podobieństwo. 

\subsection*{Metoda Householdera}

Metoda Householdera pozwala znaleźć rozkład QR dowolnej macierzy prostokątnej m x n ($m\ge n$).

{Macierz Householdera}
Macierzą Householdera H zwaną również refleksją nazywamy symetryczną i ortogonalną macierz przekształcenia wektora, które odbija go względem pewnej płaszczyzny. 
\newpage
{Transformacja Householdera}
Niech  $v\in R^{m}, $ i $v\neq 0. $ Wówczas transformacją Householdera nazywamy macierz postaci:

$${\displaystyle H=I-Wvv^{T}, } {\displaystyle H=I-Wvv^{T}, }       {\displaystyle W={\frac {2}{v^{T}v}}} {\displaystyle W={\frac {2}{v^{T}v}}}$$ 
Macierz H jest macierzą symetryczną i ortogonalną oraz ma taką własność, że dowolny wektor x wymiaru m jest odbiciem lustrzanym wektora Hx względem hiperpłaszczyzny (wymiaru m-1) prostopadłej do wektora v[3]. Łatwo sprawdzić, że tak jest ponieważ: 

$${\displaystyle H^{2}=\left(I-{\frac {2vv^{T}}{v^{T}v}}\right)^{2}=I-{\frac {4vv^{T}}{v^{T}v}}+4\left({\frac {vv^{T}}{v^{T}v}}\right)^{2}=I} {\displaystyle H^{2}=\left(I-{\frac {2vv^{T}}{v^{T}v}}\right)^{2}}$$ \newline  $$= {I-{\frac {4vv^{T}}{v^{T}v}}+4\left({\frac {vv^{T}}{v^{T}v}}\right)^{2}=I}       {\displaystyle ((vv^{T})(v^{T}v)=(vv^{T})^{2})} {\displaystyle ((vv^{T})(v^{T}v)=(vv^{T})^{2})}$$\\
oraz\\

$${\displaystyle H^{T}=\left(I-{\frac {2vv^{T}}{v^{T}v}}\right)^{T}=I-\left({\frac {2vv^{T}}{v^{T}v}}\right)^{T}=I-{\frac {2vv^{T}}{v^{T}v}}=H} {\displaystyle H^{T}=\left(I-{\frac {2vv^{T}}{v^{T}v}}\right)^{T}}$$ \newline $$={I-\left({\frac {2vv^{T}}{v^{T}v}}\right)^{T}=I-{\frac {2vv^{T}}{v^{T}v}}=H}       {\displaystyle ((vv^{T})^{T}=(vv^{T}))} {\displaystyle ((vv^{T})^{T}=(vv^{T}))}$$\\
Z drugiej równości wynika symetria, z pierwszej ortogonalność, ponieważ $${\displaystyle H^{T}H=HH=I}. $$ Zatem:\\

$${\displaystyle |Hx|={\sqrt {(Hx)^{T}(Hx)}}={\sqrt {x^{T}(H^{T}H)x}}={\sqrt {x^{T}Ix}}=|x|} {\displaystyle |Hx|={\sqrt {(Hx)^{T}(Hx)}}={\sqrt {x^{T}(H^{T}H)x}}={\sqrt {x^{T}Ix}}=|x|}. $$\\
Mnożąc dowolny wektor ${\displaystyle x\in R^{m}}$ otrzymujemy:\\

$${\displaystyle Hx=x-{\frac {2vv^{T}x}{v^{T}v}}=x+(-2{\frac {vv^{T}x}{v^{T}v}})=x-2r} {\displaystyle Hx=x-{\frac {2vv^{T}x}{v^{T}v}}=x+(-2{\frac {vv^{T}x}{v^{T}v}})=x-2r}$$





\chapter{Eksperymenty numeryczne}

\chapter{Podsumowanie}


\bibliographystyle{plain}
\bibliography{bibliografia}

\end{document}